---
title: "Linear models with categories and ANOVA"
format: html
editor: source
---

```{r}
#| label: load-packages
#| include: false

library(tidyverse)
library('DT')
library(LaCroixColoR)
palette(lacroix_palette("Mango", type = "discrete"))
library(emmeans)
library(broom)
library(cowplot)
library(plotly)
library('palmerpenguins')
```

## What are we doing here?

We previously discussed linear models and learned to build a very simple linear model to estimate the mean. We also learned how to calculate residuals, which in this case were the differences between each datapoint and the mean.

In this section we'll expand our linear model to incorporate differences between categories.

We'll also cover ANOVA, which lets us determine how much variation is explained by a category.

## Motivating example

You may have noticed in the plot of penguin body mass in the last chapter that there appeared to be differences between different groups. Let's look more closely by making a plot of the body masses by color.

```{r}
plot(penguins$body_mass_g, bty="n", ylab = "body mass", 
     col=penguins$species, lwd=2)
legend('topleft',levels(penguins$species),bty="n", pch=1, pt.lwd=2, col=palette())

```

It definitely looks like something is different between these different species.
But can we use linear models to confidently say so?

## Linear models with categories

Let's walk through how to use a linear model to estimate the differences between categories

### Estimating conditional means

```{r}
#| echo: false
#| column: margin
#| fig-alt: "Four penguins on a rock"
#| fig-cap: "Adelie Penguins -- By cyfer13 - IMG_1815, CC BY 2.0, https://commons.wikimedia.org/w/index.php?curid=4048994" 
library(knitr)
include_graphics("figs/Adelie_Penguin2.jpg")
```


We want to start by estimating the mean body mass of each species of penguin. 
The code below does this

```{r}
penguins                                             |>
  filter(!is.na(body_mass_g) , !is.na(species)) |>  #remove NAs
  group_by(species)                             |>
  summarise(mean_body_mass_g = mean(body_mass_g))
```

You may be wondering why I am referring to this as a conditional mean.
To explain this I'll walk through the math of the model, focussing only on Adelie and Gentoo penguins.

We will model body mass of an individual penguin, $i$, conditional on its species.

$$\text{Mass}_i = b_0 + b_1 \times \text{Adelie}_i + e_i $$

* $b_0$ is the intercept and, in this case, the mean body mass of Gentoo penguins
* $b_1$ is the difference in mass between Adelie and Gentoo penguins.
* $\text{Adelie}_i$ is an indicator variable that is $1$ if individual $i$ is an Adelie penguin and $0$ if individual $i$ is a Gentoo penguin.
* $e_i$ is the residual 

We could rewrite the above equation as two equations that describe the mass of individuals conditional on whether they are Adelie or Gentoo.
$$ \text{Mass}_{i|\text{Gentoo}} = b_0 + e_i$$
$$ \text{Mass}_{i|\text{Adelie}} = b_0 + b_1 + e_i$$

We can work through these equations to estimate the parameters of the model. The mean mass of an Adelie penguin ($b_0$) is 3701 and since the mean mass of a Gentoo penguin is 5076, $b_1 = 1375$.

### Fitting a model with lm()

```{r}
## first filter out chinstraps and anything with missing data
penguins2 <- penguins                                             |>
  filter(!is.na(body_mass_g) , species != "Chinstrap") |> 
  droplevels()

model1 <- lm(body_mass_g ~ species, data=penguins2)
summary(model1)
```

### Residuals

The residuals of this model will be the difference between each data point and the conditional means estimated by the model.

```{r, echo=F, label="fig-plotly",message=F, warning=F, cap.location=margin, fig.cap="An interactive plot showing the mean body size of a penguin. Each point represents an individual penguin, and the dashed red line shows model predicted means. Hovering over a point reveals its residual — the difference between the observed value and the mean.", fig.alt="Interactive scatterplot of observed mean body mass of penguins. Points are plotted by index along the x-axis, with predicted body mass on the y-axis. A horizontal dashed lines mark the conditional means for each category. When hovering over a point, the residual (difference between the point’s value and the mean) is displayed."}

resid_plot <- penguins2                          |>
  mutate(i = 1:n(),
         e_i = body_mass_g - mean(body_mass_g),
         e_i = round(e_i, digits = 3),
         y_hat_i = round(mean(body_mass_g),digits=3),
         y_i = round(body_mass_g, digits = 3))                         |>
  ggplot(aes(x = i, y = y_i, y_hat_i = y_hat_i, e_i = e_i, colour=species))+
  geom_point(size = 4, alpha = .6)+
  scale_color_manual(values = palette()[1:2])+
  geom_hline(data = penguins2    |> 
               group_by(species)|> 
               summarise(body_mass_g = mean(body_mass_g)),
             aes(yintercept = body_mass_g, colour=species), linetype = "dashed", linewidth = 2)+
  labs(y = "Body Mass", title ="This plot is interactive!! Hover over a point to see its residual")+
  theme(legend.position = "none")

ggplotly(resid_plot)
```

:::fyi
**Linear models vs t-tests**

How is what we've just done different from a t-test? Or is it?

```{r}
adelies = dplyr::filter(penguins, species=="Adelie")
gentoos = dplyr::filter(penguins, species=="Gentoo")

t.test(adelies$body_mass_g, gentoos$body_mass_g)

```

Both a t-test and the linear models we've discussed so far are based on a normal distribution.
However, the t-test uses a t distribution. The t-distribution incorporates uncertainty in our estimate of the standard deviation of a normal distribution. The more data we have, the closer the t-distribution approximates a normal distribution.

Note that we can compare the output of our t.test above and the summary of the corresponding linear model and the t-value for species is the same!

:::


### More than two categories

What if we want to look at all three species? We can use the same modelling approach as before.

$$\text{Mass}_i = b_0 + b_1 \times \text{Adelie}_i +b_2 \times \text{Chinstrap} + e_i $$

* $b_0$ is the intercept and, in this case, the mean body mass of Gentoo penguins
* $b_1$ is the difference in mass between Adelie and Gentoo penguins.
* $b_2$ is the difference in mass between Chinstrap and Gentoo penguins.
* $\text{Adelie}_i$ is an indicator variable that is $1$ if individual $i$ is an Adelie penguin and $0$ if not.
* $\text{Chinstrap}_i$ is an indicator variable that is $1$ if individual $i$ is a Chinstrap penguin and $0$ if not.
* $e_i$ is the residual 

### Building a model with more than two categories with lm()

```{r}
model2 <- lm(body_mass_g ~ species, data = penguins)
model2
summary(model2)
```

### A note on the reference categories.

Our model will look slightly different depending on which reference category we use. 
In the previous model, our reference category was Gentoo since it is the mean body mass of Gentoo penguins that is equal to the intercept. 
We can change the reference category.

The code below runs a new model that uses the relevel() function to set the reference as Chinstrap.

```{r}
model3 <- lm(body_mass_g ~relevel(species, ref="Chinstrap"), data=penguins)
model3
```

## ANOVA

There may be times where we have multiple category values but instead of knowing the effect of each category value on the outcome, we just want to know if individuals from different species have different body masses in general.
For example, if we had 100s of penguin species, we might care less about the effect of each species than how much species matter in general. This latter value would be easier to interpret.

Answering this question requires an ANOVA, which stands for "Analysis of Variance"
Formally, we are asking if individuals from different groups are drawn from the same distribution (our null hypothesis) or different distributions (our alternative hypothesis).

The ANOVA also solves some other problems with multiple category linear models. The model above compares Gentoo and Chinstrap penguins with Adelie penguins but it doesn't compare Gentoo and Chinstrap with each other. Making that comparison requires rearranging the order of the model. 

###

ANOVAs work by estimating the amount of variation within groups and among groups.
The null hypothesis suggests that individuals from different groups will be no more different from each other than individuals from the same group.
If this is true, then the variance among groups should equal the variance within groups.

We need ways to measure this variance. We'll start by describing the *sum of squares groups*. $\text{SS}_{\text{group}} =  \Sigma_{i} n_{i}(\hat{Y_i} - \bar{Y})^{2}$ where $\hat{Y_i}$ is the mean of the $i^{th}$ group, $n_i$ is the number of individuals in the group, and $\bar{Y}$ is the mean of the entire sample. The differences between the model mean and the mean of the whole sample are shown in panel b below.

The corresponding value within groups is$\text{SS}_{\text{error}}$m the *sum of squares error*. It is calculated as $\text{SS}_{\text{error}} = \Sigma_{i}\Sigma{j}(Y_{ij} - \bar{Y_i})^2$ where $Y_{ij}$ is the value for each individual $j$ in group $i$. The differences between each individual and the group means are shown in panel c below.

Together, the error mean square and the group mean square sum to the total mean square which tells us the deviations between each individual and the group mean (panel c below).

```{r, echo=FALSE, warning=FALSE,fig.cap = "Partitioning deviations in an ANOVA. **A** Shows the difference between each observation, $Y_i$, and the grand mean, ${\\overline{Y}}$. This is the basis for calculating $SS_{total}$.  **B** Shows the difference between each predicted value $\\widehat{Y_i}$ and the grand mean, ${\\overline{Y}}$. This is the basis for calculating $SS_{group}$. **C** Shows the difference between each observation, $Y_i$, and its predicted value  $\\widehat{Y_i}$. This is the basis for calculating $SS_{error}$.", fig.height=2.3, fig.width=7.6}
a <- ggplot(mutate(penguins, id = 1:n(), mean_mass = mean(body_mass_g, na.rm=T)) , 
            aes(x = id, y = body_mass_g, color = species))+
  geom_point(alpha = .5)+
  geom_hline(aes(yintercept = mean_mass))+
  geom_segment(aes( xend = id, yend = mean_mass ), 
               color = "black", alpha = .5)+
  theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank())+ 
  labs(title = "Total deviation               = ")+
  scale_color_manual(values = palette()[c(1:3)])

b<-ggplot(mutate(augment(model2), id = 1:n(), mean_mass = mean(body_mass_g, na.rm=T)) ,
          aes(x = id, y = body_mass_g, color = species))+
  geom_point(alpha = .5)+
  geom_hline(aes(yintercept = mean_mass))+
  geom_segment(aes( xend = id,y = .fitted,  yend = mean_mass ), 
               color = "black", alpha = .5)+
    geom_line(aes(y = .fitted), alpha  = 2)+ 
    theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank())+ 
  labs(title = "Groups deviation             +")+
  scale_color_manual(values = palette()[c(1:3)])

c<-ggplot(mutate(augment(model2), id = 1:n(), mean_mass = mean(body_mass_g, na.rm=T)) ,
          aes(x = id, y = body_mass_g, color = species))+
  geom_point(alpha = .5)+
  geom_hline(aes(yintercept = mean_mass))+
  geom_segment(aes( xend = id,  yend = .fitted), 
               color = "black", alpha = .5)+
    geom_line(aes(y = .fitted), alpha  = 2)+ 
    theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank())+ 
  labs(title = "Error deviation")+
  scale_color_manual(values = palette()[c(1:3)])

plot_grid(plot_grid(a + theme(legend.position = "none"),
          b + theme(legend.position = "none"),
          c + theme(legend.position = "none"), ncol = 3, labels = c("a","b","c"), label_y = .9),
           get_legend(a+theme(legend.position = "bottom")), 
                      ncol = 1, rel_heights = c(1,.1))
```


### Significance with an F statistic

So remember that if there is no difference in means between groups, the variance within groups will be the same as the variance between groups. 

ANOVAs test this claim using a F statistic which calculates the ratio of these two values. 


$$ F = \frac{\text{Variance among groups}}{\text{Variance within groups}}$$

While different terms are used across texts, here we will call the variance among groups is called the **group mean square** or $\text{MS}_{\text{groups}}$ and it is calculated as $\text{MS}_{\text{groups}} =  \frac{\text{SS}_{\text{groups}}}{df_{\text{groups}}}$. In this case $df_{\text{groups}} = n_{\text{groups}} - 1$.

The variance within groups will be called the **error mean square** or $\text{MS}_{\text{error}}$ and is calculated as $\text{MS}_{\text{error}}  = \frac{\text{SS}_{\text{error}}}{df_{\text{error}}}$. Here, $df_{\text{error}}= n- n_{\text{groups}}$.

$$ F = \frac{\text{MS}_{\text{groups}}}{\text{MS}_{\text{error}}}$$

Using our penguin data we can calculate the sum of squares values
```{r}
penguins2 <- filter(penguins, !is.na(body_mass_g)) #remove nas for body mass

sstable <- augment(model2) |> ## give us the means of each group in the .fitted row
     mutate(sample_mean  = mean(body_mass_g)) |> # calculate the total mean
            summarise(n_groups = n_distinct(species),
                      n=n(),
        SS_total = sum((body_mass_g-sample_mean)^2), #total ss from body mass minus sample mean
        SS_groups=sum((.fitted-sample_mean)^2), #model ss from group means minus total mean
        SS_error = sum((body_mass_g-.fitted)^2), # error ss from body mass minus the group means
)
 
sstable
 
```

Next we can calculate the mean square values
```{r}
ftable <- sstable |>
  mutate(
    df_groups = n_groups-1,
    df_error = n - n_groups,
    ms_groups = SS_groups/df_groups,
    ms_error = SS_error/df_error,
    F_value = ms_groups/ms_error
  )

ftable
```

We can then use an F-test to test the hypothesis that F is different from 1.

```{r}
pf(q = ftable$F_value, df1 = ftable$df_groups, df2 = ftable$df_error, lower.tail = FALSE)
```

### Fitting an ANOVA with in R

Instead of calculating everything by hand, we can use R to fit an ANOVA with the following code:

```{r, message=FALSE}
#install.packages('car')
library(car)

Anova(model2)
```

Note that our calculations match the Anova function!

### Pairwise comparisons

Now, to determine if there is a difference between any pair of categories, like Chinstrap and Gentoo, we can do a post-hoc pairwise comparison. **Post-hoc** tells us that we are doing these tests after we reject the null hypothesis that all of these categories have the same distribution.

If we want to look at all possible comparisons, this is called doing **unplanned comparisons**

```{r, message=FALSE}
#install.packages("emmeans")
library(emmeans)

out.emmeans <- emmeans(model2, specs = "species")
pairs(out.emmeans)
```

### Assumptions of an ANOVA

1. Equal variance within groups
The ANOVA null hypothesis is that variance within groups is the same as variance between groups, so having different amounts of variance within different groups will break the null hypothesis.

A general rule of thumb is that as long as the variances of each group are within a factor of five of each other, you can use an ANOVA.

2. Normally distributed residuals

This assumption is similar to what we have in a linear model. Fortunately, ANOVAs are pretty robust to this assumption

## Review questions

Maize pollen can provide food for *Anopheles arabiensis*, a vector of malaria. Imagine that you are interested in whether maize cultivation levels affect malaria levels. You have data from Kebede et al. 2005 on maize cultivation level and rates of malaria from multiple locations in Ethiopia.

Here is a plot of the data below

```{r, echo=F, eval=T}
mm <- read.csv('~/Documents/msu-eeb830831-quarto/data/malaria_v_maize.csv')

mm$yield = factor(mm$maize_yield, levels=c('Low','Medium','High'))

ggplot(data = mm, aes(x = yield, y = incidence_rate_per_ten_thousand)) + 
  geom_jitter(height = 0, width = .2, size = 2, alpha = .35, show.legend = FALSE)+
 # geom_boxplot(fill = 'gray') + 
  theme_bw(base_size = 18) + 
  labs(x = 'maize yield', y = 'malaria rate')

```

1. Write out an equation for a linear model testing for the effects of each yield category on malaria rates. Define each variable in the model (all the $b$ values)

2. What if you were interested in whether yield in general affected malaria rate? Would you use a linear model or an ANOVA? Why?

3. Does it look like this data matches the assumptions of an ANOVA? If not, why not?




