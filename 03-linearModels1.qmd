---
title: "Linear Models 1: The Mean"
format: html
editor: source
---

```{r}
#| label: load-packages
#| include: false

library(tidyverse)
```

## What are we doing here?

In this chapter, we will meet the linear model and discuss what it is exactly that we are doing when we build linear models.

We'll build the most basic type of linear model by fitting the mean of a distribution.

We'll also learn to interpret residuals and visualize them with R.

## Linear models

As biologists, we often want to understand if one thing causes another thing.

* Do traits determine an organism's fitness? In other words, are traits under selection?
* Does genotype at this locus determine phenotype?
* Do the amount of resources shape community diversity?
* **get Lauren et al to fill in some other questions**

To answer these types questions, we need a way to carefully relate two variables together. We will refer throughout this course to two types of variables:

1. Explanatory variables, also called independent variables or predictor variables.
2. Response variables, also called dependent variables.

Linear models estimate the conditional mean of the $i^{th}$ observation of a continuous response variable, $\hat{Y}_i$ from a (combination) of value(s) of the explanatory variables ($\text{explanatory variables}_i$): 

\begin{equation} 
\hat{Y}_i = f(\text{explanatory variables}_i)
\end{equation} 

These models are "linear" because we estimate of the conditional mean ($\hat{Y}_i$) by adding up all components of the model. So, each explanatory variable $y_{j,i}$ is multiplied by its effect size $b_j$. It might help to look at an example model below:

\begin{equation} 
\hat{Y}_i = a + b_1  y_{1,i} + b_2 y_{2,i} + \dots{}
\end{equation}

In this example, $\hat{Y}_i$ is estimated as the sum of the "intercept" ($a$), its value for the first explanatory variable ($y_{1,i}$) times the effect of this variable ($b_1$), its value for the second explanatory variable ($y_{2,i}$) times the effect of this variable, $b_2$, and so on for all included explanatory variables.

In practice, fitting a linear model requires picking explanatory variables and then estimating the values of $a$, $b_1$, $b_2$, and so on that best predict the response variables. These estimates then tell us how the explanatory variables relate to the response variable.

## The mean

We are going to start with the simplest linear model possible. You likely already know how to calculate the mean ($\overline{y}$) of a set of data: $\overline{y} = \frac{\sum y_i}{n}$ where $y_i$ is each data point and $n$ is the number of samples.

In the simplest linear model we can also think of the mean as the intercept ($b_0$) so 
we can predict each data point $y_i$ as simply the mean plus an error term or residual ($e_i$).

$$\hat{y}_i = b_0 + e_i$$

### Wait, what's a residual?

Observed values often differ from the predictions made by a linear model.

We define a residual ($e_i$) as the difference between an observed value($Y_i$) and its predicted value from a linear model  ($\hat{y}_i$).


$$e_i = y_i - \hat{y}_i$$

You can also rearrange this to think about it the other way around so that the observed variable ($Y_i$) is the sum of the value predicted by the model ($\hat{y}_i$) and the residual $e_i$.

$$y_i = \hat{y}_i + e_i$$

## Using R's lm() function 

You can use the lm() function to build a linear model in R.

Throughout this section we'll be using a dataset of penguin traits. This data should be already available in your version of R, but if it isn't, use the following code to install it.

```{r, eval=F}
install.packages("palmerpenguins")
library("palmerpenguins")
```

You can read more about all the variables available in the package

```{r}
?penguins
```

We'll start by thinking about body size. We want to model each penguin's body mass as the sum of a mean body mass and a residual.

$$\text{penguin body mass} = \text{mean body mass} + e_i$$



Below is code for this linear model.


```{r}
model1 = lm(body_mass ~ 1, data = penguins)
model1
```

The output gives us the estimated intercept — which, in this case with no predictors, is simply the mean

We can also use the summarize() function to look more carefully at the model

```{r}
summary(model1)
```

We can update our model from above with our new parameter estimate of the mean.

$$\text{penguin body mass} = 4201.75 + e_i$$



## More on residuals

The residual ($e_i$) for each individual penguin tells us how much that penguin's mass differs from the population mean.


For example, we can look at one specific penguin

```{r}
penguins[1,]

```

This is a male Adelie penguin from Torgersen Island. Its body mass is 3750. We can describe this penguin's mass as

$$3750 = 4201.75 + e_i$$
$e_i = 4201.75-3750 = 451.75$


Below I plot all the body mass data. Each point is a penguin. You can hover over the points to see the body mass of each penguin and the residual.

```{r, eval=F}
#| code-fold: true
#| message: false
#| warning: false
#| label: fig-plotly
#| fig-cap: "An interactive plot showing the mean body size of a penguin. Each point represents an individual penguin, and the dashed red line shows the sample mean across all penguins. Hovering over a point reveals its residual — the difference between the observed value and the mean."
#| fig-alt: "Interactive scatterplot of observed mean body mass of penguins. Points are plotted by index along the x-axis, with body mass on the y-axis. A horizontal dashed red line marks the sample mean. When hovering over a point, the residual (difference between the point’s value and the mean) is displayed."
#| cap-location: margin
library(plotly)
prop_hybrid_plot <- penguins                          |>
  filter(!is.na(body_mass))                         |>
  mutate(i = 1:n(),
         e_i = body_mass - mean(body_mass),
         e_i = round(e_i, digits = 3),
         y_hat_i = round(mean(body_mass),digits=3),
         y_i = round(body_mass, digits = 3))                         |>
  ggplot(aes(x = i, y = y_i, y_hat_i = y_hat_i, e_i = e_i))+
  geom_point(size = 4, alpha = .6)+
  scale_color_manual(values = c("black","darkgreen"))+
  geom_hline(yintercept = 4201.76,
             linetype = "dashed", color = "red", size = 2)+
  labs(y = "Body Mass", title ="This plot is interactive!! Hover over a point to see its residual")+
  theme(legend.position = "none")

ggplotly(prop_hybrid_plot)
```

## Generating residuals.

You can look at residuals and model predictions using the augment() function in the broom package. 
The code below uses augment() to make a table where each row has a penguin's body mass, the expectation 
of body mass from the fitted model, and the residual.


```{r}
#install.packages('broom')  ##uncomment this code to install the broom package
library(broom)

augment(model1) |> select(body_mass, .fitted, .resid)
                          
```

You could also generate residuals without any additional packages by using the following code

```{r}
penguins2 <- penguins |> filter(!is.na(body_mass)) ##filter out ones with NAs
model1Residuals <-  penguins2$body_mass - model1$fitted.values

```


## Calculating the $SS_residual$ 

TODO explain why if we're doing this 
```{r}
library(broom)
model1       |>
 augment()                |>
 mutate(sq_resid=.resid^2)|>
 summarise(SS=sum(sq_resid))

```


## The mean minimixes $SS_residual$
