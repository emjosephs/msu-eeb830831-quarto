---
title: "Linear models with continuous variables"
format: html
editor: source
---

```{r}
#| label: load-packages
#| include: false

library(tidyverse)
library('DT')
library(LaCroixColoR)
palette(lacroix_palette("Mango", type = "discrete"))
```

## What are we doing here?

Many of the variables you are interested are continuous, not categorical. In this section we'll extend our linear models to incorporate continuous predictor variables.

## Motivating example

Continuing with the penguin example data, imagine that we are interested in understanding how bill length determines body mass -- do penguins with longer bills also have larger bodies?

```{r}
penguins2 <- penguins |> filter(!is.na(body_mass) & !is.na(bill_len)) ##filter out ones with NAs
plot(penguins2$bill_len, penguins2$body_mass, bty="n", ylab = "body mass", xlab = "bill length", lwd=2, col = palette()[1])

```

We can plot out the data and see that there is potentially a relationship between bill length and body mass. But, imagine we have a biological reason for wanting to model body mass as a function of bill length. How would we do that?

## Starting with categories

In the last section we learned about testing for differences between categorical predictor variables. 
We could start there to think about how to approach this challenge.
Specifically, imagine we divide our penguins in half and compare body mass between the half with longer bills and the half with shorter bills.

We'll start by making a categorical variable, "long", that is true if a penguin's bill length is greater than the median bill length and otherwise false.
```{r}
penguins2 <- mutate(penguins2, long = bill_len>median(bill_len))

```

Next, we will see if long bill length predicts mass, using a categorical model:

$$\text{Mass}_i = b_0 + b_1 \times \text{Long}_i + e_i $$
Now, let's fit this model with lm()

```{r}
model1 <- lm(body_mass ~ long, data = penguins2)
summary(model1)
```

We get a pretty strong signal that the long-billed penguins are larger than small-billed penguins since $b_1$ is estimated to be 872.22, which is the difference in means between long-billed and short-billed penguins.

You are likely shaking your head at this model, since we are losing a lot of information about our data by collapsing what we have into two means. In fact, doing this type of collapsing of continuous data into categorical data is often a really bad idea for multiple reasons.

NOTE IS THIS A GOOD APPROACH I DON'T KNOW


## Linear models with continuous predictors

Instead of letting the mean of the model vary between categories, we now build our model with the mean as a linear function of the predictor variable. This model is called **linear regression** and it has two components: the **determenistic function** and the **stochastic function**

### The deterministic function

The deterministic function describes how the explanatory variables relate to the conditional mean of the response variable. In this case, since this is a linear model, we are modelling the response variable as a line:

$$\hat{y}_i = b_0 + b_1 \times x_i$$
As before, $y_i$ is the conditional mean of the response variable for an individual with value $x_i$, $b_0$ is the intercept or the conditional mean of an individual with a value of $x_i = 0$ (although this value will not be meaningful if it lies far outside the range of the data). 

However, we can think of $b_1$ now as the slope of the relationship between the predictor and response variable. This means that for every increase of 1 unit in $x$, $y$ increases by $b_1$.

### The stochastic function

The **stochastic function** explains how the residuals are distributed around the conditional means predicted by the deterministic function. Since we are working with regular linear models, we will assume that the residuals are normally distributed.

$$ e_i \sim N(0, \sigma^2)$$

We can combine the deterministic and stochastic functions into one model:

$$y_i = \hat{y}_i + N(b_0 + b_1 \times x_i, \sigma^2)$$



## Estimating parameters

$$b_1 = \frac{cov_{x,y}}{s^2_x}  =  \frac{\frac{1}{(n-1)}\sum(x_i-\bar{x})(y_i-\bar{y})}{\frac{1}{(n-1)}\sum(x_i-\bar{x})^2}=\frac{\sum(x_i-\bar{x})(y_i-\bar{y})}{\sum(x_i-\bar{x})^2}$$ 

(only include this if we do variance and covariance somewhere)

## Likelihood and linear models

## Fitting with lm()

Let's try applying a linear model to our penguin data. We'll use the lm() function in R.

$$\text{Body mass}_i = b_0 + b_1 \times \text{Bill length}_i $$

```{r}
model1 <- lm(body_mass ~ bill_len, data=penguins2)
model1
```

Based on these estimates, we can now write out our model as


$$\text{Body mass}_i = 362.31 + 87.42 \times \text{Bill length}_i $$

We can interpret this as for every mm of bill length increase, body mass increases by 87 grams.

We can also estimate $\sigma^2$, the variance of the residuals.

```{r}
sigma(model1)

```

This allows us to write our model including the stochastic function as:

$$ \text{Body mass}_i \sim N(362.31 + 87.42 \times \text{Bill length}_i, 645.43) $$ 

We can also plot the predictions from this model over the raw data.

```{r}
plot(penguins2$bill_len, penguins2$body_mass, bty="n", ylab = "body mass", xlab = "bill length", lwd=2, col = palette()[1])
abline(model1, col=palette()[3], lwd=2)

```

### Fitting with glmmTMB()

### Residuals

It can be a bit confusing to think about the distribution of residuals in these types of models. Often we assume that the response data needs to be normally distributed to use a linear model. However, the real assumption of the model is not that the response data is normally distributed, but that the residuals are normally distributed.

Let's look at the residuals from this model
```{r}
library(broom)
myResiduals <- augment(model1) |> select(body_mass, .fitted, .resid)

hist(myResiduals$.resid, main="", xlab = "residuals", border="white", col=palette()[2])
```

It helps me to imagine that the values themselves follow a normal distribution centered around a mean that follows the model predictions.

```{r, echo=F}

par(mfrow=c(1,2))

plot(penguins2$bill_len, penguins2$body_mass, bty="n", ylab = "body mass", xlab = "bill length", lwd=2, col = palette()[1])
abline(model1, col=palette()[3], lwd=2)
abline(v=40, col=palette()[2], lty=2, lwd=2)
abline(v=47, col=palette()[4], lty=2, lwd=2)
abline(v=54, col=palette()[5], lty=2, lwd=2)



#hist(rnorm(mean=model1$coefficients[1]+model1$coefficients[2]*40, sd = sigma(model1), n=1000), main="", xlab = "body mass", border="white", col=palette()[2], freq=F, xlim=c(2000, 7000))

#hist(rnorm(mean=model1$coefficients[1]+model1$coefficients[2]*47, sd = sigma(model1), n=1000), main="", xlab = "body mass", border="white", col=palette()[4], freq=F, xlim=c(2000, 7000))

#hist(rnorm(mean=model1$coefficients[1]+model1$coefficients[2]*54, sd = sigma(model1), n=1000), main="", xlab = "body mass", border="white", col=palette()[5], freq=F, xlim=c(2000, 7000))


### OR

plot(-5,-5, xlim = c(2000,7000), ylim = c(0,0.0006), xlab = "body mass", ylab = "", bty="n")
lines(seq(2000,7000,length.out=100),
									dnorm(seq(2000,7000,length.out=100),
									mean=model1$coefficients[1]+model1$coefficients[2]*40,
									sd=sigma(model1)),
                  col = palette()[2], lwd=2, lty=2)

lines(seq(2000,7000,length.out=100),
									dnorm(seq(2000,7000,length.out=100),
									mean=model1$coefficients[1]+model1$coefficients[2]*47,
									sd=sigma(model1)),
                  col = palette()[4], lwd=2, lty=2)

lines(seq(2000,7000,length.out=100),
									dnorm(seq(2000,7000,length.out=100),
									mean=model1$coefficients[1]+model1$coefficients[2]*54,
									sd=sigma(model1)),
                  col = palette()[5], lwd=2, lty=2)

```



```{r, echo=F, eval=F}
## some noodling to convince myself of stuff

myExp = runif(500)*100
myResp = myExp + rnorm(500, sd=10) 

plot(myExp, myResp)

myModel <- lm(myResp ~ myExp)

sigma(myModel)

```

